{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "dfffc269-d57f-4800-ac28-ba191fd557da",
   "metadata": {},
   "outputs": [],
   "source": [
    "from selenium import webdriver\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.support.ui import Select\n",
    "from bs4 import BeautifulSoup\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "53d78f48-e994-4c67-8834-687549efe5f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "years = [\n",
    "    '1987-88', '1988-89', '1990-91', '1991-92', '1992-93', '1993-94', '1994-95', '1995-96', '1996-97',\n",
    "    '1997-98', '1998-99', '1999-00', '2000-01', '2001-02', '2002-03', '2003-04', '2004-05', '2005-06', '2006-07',\n",
    "    '2007-08', '2008-09', '2009-10', '2010-11', '2011-12', '2012-13', '2013-14', '2014-15', '2015-16', '2016-17',\n",
    "    '2017-18', '2018-19', '2019-20', '2020-21', '2021-22', '2022-23', '2023-24 (April-December)'\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c8ed0c06-426a-44d9-94ec-a6f0c4f79f28",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Scrapping Data of year 1987-88\n",
      "Scrapping Data of year 1988-89\n",
      "Scrapping Data of year 1990-91\n",
      "Scrapping Data of year 1991-92\n",
      "Scrapping Data of year 1992-93\n",
      "Scrapping Data of year 1993-94\n",
      "Scrapping Data of year 1994-95\n",
      "Scrapping Data of year 1995-96\n",
      "Scrapping Data of year 1996-97\n",
      "Scrapping Data of year 1997-98\n",
      "Scrapping Data of year 1998-99\n",
      "Scrapping Data of year 1999-00\n",
      "Scrapping Data of year 2000-01\n",
      "Scrapping Data of year 2001-02\n",
      "Scrapping Data of year 2002-03\n",
      "Scrapping Data of year 2003-04\n",
      "Scrapping Data of year 2004-05\n",
      "Scrapping Data of year 2005-06\n",
      "Scrapping Data of year 2006-07\n",
      "Scrapping Data of year 2007-08\n",
      "Scrapping Data of year 2008-09\n",
      "Scrapping Data of year 2009-10\n",
      "Scrapping Data of year 2010-11\n",
      "Scrapping Data of year 2011-12\n",
      "Scrapping Data of year 2012-13\n",
      "Scrapping Data of year 2013-14\n",
      "Scrapping Data of year 2014-15\n",
      "Scrapping Data of year 2015-16\n",
      "Scrapping Data of year 2016-17\n",
      "Scrapping Data of year 2017-18\n",
      "Scrapping Data of year 2018-19\n",
      "Scrapping Data of year 2019-20\n",
      "Scrapping Data of year 2020-21\n",
      "Scrapping Data of year 2021-22\n",
      "Scrapping Data of year 2022-23\n",
      "Scrapping Data of year 2023-24 (April-December)\n"
     ]
    }
   ],
   "source": [
    "# Getting Yearly Data ProductWise\n",
    "\n",
    "for k in range(0, len(years)):\n",
    "    options = webdriver.ChromeOptions()\n",
    "    options.add_argument(\"--headless\")\n",
    "    browser = webdriver.Chrome(options=options)\n",
    "    browser.get(\"https://agriexchange.apeda.gov.in/IndExp/PortNew.aspx\")\n",
    "    print(f\"Scrapping Data of year {years[k]}\")\n",
    "    \n",
    "    product_element = browser.find_element(By.ID, \"RBLSummary_3\")\n",
    "    product_element.click()\n",
    "    \n",
    "    year_element = browser.find_element(By.ID, \"ListBoxYear\")\n",
    "    year_dropdown = Select(year_element)\n",
    "    year_dropdown.select_by_visible_text(years[k])\n",
    "    \n",
    "    value_element = browser.find_element(By.ID, \"Crore\")\n",
    "    value_element.click()\n",
    "    \n",
    "    submit_element = browser.find_element(By.ID, \"Button1\")\n",
    "    submit_element.click()\n",
    "    \n",
    "    html_content = browser.page_source\n",
    "    doc = BeautifulSoup(html_content, \"html.parser\")\n",
    "    \n",
    "    table_element = doc.find_all(\"table\")\n",
    "    table = table_element[11]\n",
    "    row_element = table.find_all(\"tr\")\n",
    "    \n",
    "    data = []\n",
    "    for i in range(2, len(row_element)):\n",
    "        internal = []\n",
    "        elements = row_element[i].find_all(\"td\")[:3]\n",
    "        for j in range(0, len(elements)):\n",
    "            internal.append(elements[j].text)\n",
    "        data.append(internal)\n",
    "    \n",
    "    df = pd.DataFrame(data, columns = [\"Product Name\", \"Qty(MT)\", \"Rs(Crore)\"])\n",
    "    df.to_csv(f\"../Datasets/Export/Export-Product-Wise/{years[k]}.csv\", index=None)\n",
    "\n",
    "    browser.quit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "184011f2-c95e-4c31-b815-c314c74c3b72",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Scrapping Data of year 1987-88\n",
      "Scrapping Data of year 1988-89\n",
      "Scrapping Data of year 1990-91\n",
      "Scrapping Data of year 1991-92\n",
      "Scrapping Data of year 1992-93\n",
      "Scrapping Data of year 1993-94\n",
      "Scrapping Data of year 1994-95\n",
      "Scrapping Data of year 1995-96\n",
      "Scrapping Data of year 1996-97\n",
      "Scrapping Data of year 1997-98\n",
      "Scrapping Data of year 1998-99\n",
      "Scrapping Data of year 1999-00\n",
      "Scrapping Data of year 2000-01\n",
      "Scrapping Data of year 2001-02\n",
      "Scrapping Data of year 2002-03\n",
      "Scrapping Data of year 2003-04\n",
      "Scrapping Data of year 2004-05\n",
      "Scrapping Data of year 2005-06\n",
      "Scrapping Data of year 2006-07\n",
      "Scrapping Data of year 2007-08\n",
      "Scrapping Data of year 2008-09\n",
      "Scrapping Data of year 2009-10\n",
      "Scrapping Data of year 2010-11\n",
      "Scrapping Data of year 2011-12\n",
      "Scrapping Data of year 2012-13\n",
      "Scrapping Data of year 2013-14\n",
      "Scrapping Data of year 2014-15\n",
      "Scrapping Data of year 2015-16\n",
      "Scrapping Data of year 2016-17\n",
      "Scrapping Data of year 2017-18\n",
      "Scrapping Data of year 2018-19\n",
      "Scrapping Data of year 2019-20\n",
      "Scrapping Data of year 2020-21\n",
      "Scrapping Data of year 2021-22\n",
      "Scrapping Data of year 2022-23\n",
      "Scrapping Data of year 2023-24 (April-December)\n"
     ]
    }
   ],
   "source": [
    "# Getting Yearly Data CountryWise\n",
    "\n",
    "for k in range(0, len(years)):\n",
    "    options = webdriver.ChromeOptions()\n",
    "    options.add_argument(\"--headless\")\n",
    "    browser = webdriver.Chrome(options=options)\n",
    "    browser.get(\"https://agriexchange.apeda.gov.in/IndExp/PortNew.aspx\")\n",
    "    print(f\"Scrapping Data of year {years[k]}\")\n",
    "    \n",
    "    product_element = browser.find_element(By.ID, \"RBLSummary_4\")\n",
    "    product_element.click()\n",
    "    \n",
    "    year_element = browser.find_element(By.ID, \"ListBoxYear\")\n",
    "    year_dropdown = Select(year_element)\n",
    "    year_dropdown.select_by_visible_text(years[k])\n",
    "    \n",
    "    value_element = browser.find_element(By.ID, \"Crore\")\n",
    "    value_element.click()\n",
    "    \n",
    "    submit_element = browser.find_element(By.ID, \"Button1\")\n",
    "    submit_element.click()\n",
    "    \n",
    "    html_content = browser.page_source\n",
    "    doc = BeautifulSoup(html_content, \"html.parser\")\n",
    "    \n",
    "    table_element = doc.find_all(\"table\")\n",
    "    table = table_element[11]\n",
    "    row_element = table.find_all(\"tr\")\n",
    "    \n",
    "    data = []\n",
    "    for i in range(2, len(row_element)):\n",
    "        internal = []\n",
    "        elements = row_element[i].find_all(\"td\")[:3]\n",
    "        for j in range(0, len(elements)):\n",
    "            internal.append(elements[j].text)\n",
    "        data.append(internal)\n",
    "    \n",
    "    df = pd.DataFrame(data, columns = [\"Country Name\", \"Qty(MT)\", \"Rs(Crore)\"])\n",
    "    df.to_csv(f\"../Datasets/Export/Export-Country-Wise/{years[k]}.csv\", index=None)\n",
    "\n",
    "    browser.quit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "10f1780f-41ee-4be7-b63c-df7524c9bca8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Scrapping Data of year 2005-06\n",
      "Scrapping Data of year 2006-07\n",
      "Scrapping Data of year 2007-08\n",
      "Scrapping Data of year 2008-09\n",
      "Scrapping Data of year 2009-10\n",
      "Scrapping Data of year 2010-11\n",
      "Scrapping Data of year 2011-12\n",
      "Scrapping Data of year 2012-13\n",
      "Scrapping Data of year 2013-14\n",
      "Scrapping Data of year 2014-15\n",
      "Scrapping Data of year 2015-16\n",
      "Scrapping Data of year 2016-17\n",
      "Scrapping Data of year 2017-18\n",
      "Scrapping Data of year 2018-19\n",
      "Scrapping Data of year 2019-20\n",
      "Scrapping Data of year 2020-21\n",
      "Scrapping Data of year 2021-22\n",
      "Scrapping Data of year 2022-23\n",
      "Scrapping Data of year 2023-24 (April-December)\n"
     ]
    }
   ],
   "source": [
    "# Getting Yearly Data StateWise\n",
    "\n",
    "for k in range(17, len(years)):\n",
    "    options = webdriver.ChromeOptions()\n",
    "    options.add_argument(\"--headless\")\n",
    "    browser = webdriver.Chrome(options=options)\n",
    "    browser.get(\"https://agriexchange.apeda.gov.in/IndExp/PortNew.aspx\")\n",
    "    print(f\"Scrapping Data of year {years[k]}\")\n",
    "    \n",
    "    product_element = browser.find_element(By.ID, \"RBLSummary_2\")\n",
    "    product_element.click()\n",
    "    \n",
    "    year_element = browser.find_element(By.ID, \"ListBoxYear\")\n",
    "    year_dropdown = Select(year_element)\n",
    "    year_dropdown.select_by_visible_text(years[k])\n",
    "    \n",
    "    value_element = browser.find_element(By.ID, \"Crore\")\n",
    "    value_element.click()\n",
    "    \n",
    "    submit_element = browser.find_element(By.ID, \"Button1\")\n",
    "    submit_element.click()\n",
    "    \n",
    "    html_content = browser.page_source\n",
    "    doc = BeautifulSoup(html_content, \"html.parser\")\n",
    "    \n",
    "    table_element = doc.find_all(\"table\")\n",
    "    table = table_element[11]\n",
    "    row_element = table.find_all(\"tr\")\n",
    "    \n",
    "    data = []\n",
    "    for i in range(2, len(row_element)):\n",
    "        internal = []\n",
    "        elements = row_element[i].find_all(\"td\")[:3]\n",
    "        for j in range(0, len(elements)):\n",
    "            internal.append(elements[j].text)\n",
    "        data.append(internal)\n",
    "    \n",
    "    df = pd.DataFrame(data, columns = [\"State Name\", \"Qty(MT)\", \"Rs(Crore)\"])\n",
    "    df.to_csv(f\"../Datasets/Export/Export-State-Wise/{years[k]}.csv\", index=None)\n",
    "\n",
    "    browser.quit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "15fbdb78-0a3d-4fcb-8f72-e72f92b56df8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Scrapping Data of year 2008-09\n",
      "Scrapping Data of year 2009-10\n",
      "Scrapping Data of year 2010-11\n",
      "Scrapping Data of year 2011-12\n",
      "Scrapping Data of year 2012-13\n",
      "Scrapping Data of year 2013-14\n",
      "Scrapping Data of year 2014-15\n",
      "Scrapping Data of year 2015-16\n",
      "Scrapping Data of year 2016-17\n",
      "Scrapping Data of year 2017-18\n",
      "Scrapping Data of year 2018-19\n",
      "Scrapping Data of year 2019-20\n",
      "Scrapping Data of year 2020-21\n",
      "Scrapping Data of year 2021-22\n",
      "Scrapping Data of year 2022-23\n",
      "Scrapping Data of year 2023-24 (April-December)\n"
     ]
    }
   ],
   "source": [
    "# Getting Yearly Data PortWise\n",
    "\n",
    "for k in range(20, len(years)):\n",
    "    options = webdriver.ChromeOptions()\n",
    "    options.add_argument(\"--headless\")\n",
    "    browser = webdriver.Chrome(options=options)\n",
    "    browser.get(\"https://agriexchange.apeda.gov.in/IndExp/PortNew.aspx\")\n",
    "    print(f\"Scrapping Data of year {years[k]}\")\n",
    "    \n",
    "    product_element = browser.find_element(By.ID, \"RBLSummary_1\")\n",
    "    product_element.click()\n",
    "\n",
    "    port_element = browser.find_element(By.ID, \"PortSelection_1\")\n",
    "    port_element.click()\n",
    "    \n",
    "    year_element = browser.find_element(By.ID, \"ListBoxYear\")\n",
    "    year_dropdown = Select(year_element)\n",
    "    year_dropdown.select_by_visible_text(years[k])\n",
    "    \n",
    "    value_element = browser.find_element(By.ID, \"Crore\")\n",
    "    value_element.click()\n",
    "    \n",
    "    submit_element = browser.find_element(By.ID, \"Button1\")\n",
    "    submit_element.click()\n",
    "    \n",
    "    html_content = browser.page_source\n",
    "    doc = BeautifulSoup(html_content, \"html.parser\")\n",
    "    \n",
    "    table_element = doc.find_all(\"table\")\n",
    "    table = table_element[11]\n",
    "    row_element = table.find_all(\"tr\")\n",
    "    \n",
    "    data = []\n",
    "    for i in range(2, len(row_element)):\n",
    "        internal = []\n",
    "        elements = row_element[i].find_all(\"td\")[:3]\n",
    "        for j in range(0, len(elements)):\n",
    "            internal.append(elements[j].text)\n",
    "        data.append(internal)\n",
    "    \n",
    "    df = pd.DataFrame(data, columns = [\"Port Type\", \"Qty(MT)\", \"Rs(Crore)\"])\n",
    "    df.to_csv(f\"../Datasets/Export/Export-Port-Wise/{years[k]}.csv\", index=None)\n",
    "\n",
    "    browser.quit()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
